{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eap-NTmRBaqe"
      },
      "source": [
        "# **The fifth in-class-exercise (40 points in total, 4/18/2023)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwa4DIYMBaqh"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training.\n",
        "\n",
        "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data.\n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM\n",
        "\n",
        "(3) KNN\n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "(7) Word2Vec\n",
        "\n",
        "(8) BERT\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison\n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yIg9L3FqBaqi"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Suppressing warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "MX5sC3FpBhAR",
        "outputId": "30a6a07e-9704-43c3-d389-6b126047d8ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d7da2dbc-9940-4609-aaf7-0bfc932b7d44\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d7da2dbc-9940-4609-aaf7-0bfc932b7d44\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving stsa-test.txt to stsa-test.txt\n",
            "Saving stsa-train.txt to stsa-train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sykiYRoVBaqk",
        "outputId": "9c1a6fb5-2201-47f7-e509-1f2e6a4f2f27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sentiment                                               Text\n",
            "0         1   a stirring , funny and finally transporting r...\n",
            "1         0   apparently reassembled from the cutting-room ...\n",
            "2         0   they presume their audience wo n't sit still ...\n",
            "3         1   this is a visually stunning rumination on lov...\n",
            "4         1   jonathan parker 's bartleby should have been ...\n"
          ]
        }
      ],
      "source": [
        "# Opening and reading the contents of the \"stsa-train.txt\" file\n",
        "with open(\"stsa-train.txt\") as txt_file:\n",
        "    lines = [line.rstrip('\\n') for line in txt_file]\n",
        "\n",
        "# Separating sentiment labels and text content from each line in the file\n",
        "sentiments = []\n",
        "texts = []\n",
        "\n",
        "for line in lines:\n",
        "    # Extracting sentiment label and text content from each line\n",
        "    sentiment = line[0]\n",
        "    text_content = line[1:]\n",
        "\n",
        "    # Appending sentiment label and text content to their respective lists\n",
        "    sentiments.append(sentiment)\n",
        "    texts.append(text_content)\n",
        "\n",
        "# Creating a DataFrame from the lists of sentiment labels and text content\n",
        "dataset = pd.DataFrame(list(zip(sentiments, texts)), columns=['Sentiment', 'Text'])\n",
        "dataset.head()\n",
        "\n",
        "# Printing the first few rows of the dataset for inspection\n",
        "print(dataset.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0p1tzqBB8IQ",
        "outputId": "bd922b1b-a83b-4a1c-8946-7b8287979ddf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMPUwZv7CIsr",
        "outputId": "9392294c-89c3-4ccd-f8c4-da356ec77b8e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "l6jnX-yvBaql",
        "outputId": "300b191d-db45-4a75-bbc9-652c6afd810e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Sentiment                                               Text  \\\n",
              "0         1   a stirring , funny and finally transporting r...   \n",
              "1         0   apparently reassembled from the cutting-room ...   \n",
              "2         0   they presume their audience wo n't sit still ...   \n",
              "3         1   this is a visually stunning rumination on lov...   \n",
              "4         1   jonathan parker 's bartleby should have been ...   \n",
              "\n",
              "                                       processedText  \n",
              "0  stirring funny finally transporting imagining ...  \n",
              "1  apparently reassembled cutting room floor give...  \n",
              "2  presume audience sit still sociology lesson ho...  \n",
              "3  visually stunning rumination love memory histo...  \n",
              "4  jonathan parker bartleby end modern office ano...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01bcc365-b079-48de-9471-9c4bf696e26b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text</th>\n",
              "      <th>processedText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>a stirring , funny and finally transporting r...</td>\n",
              "      <td>stirring funny finally transporting imagining ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>apparently reassembled from the cutting-room ...</td>\n",
              "      <td>apparently reassembled cutting room floor give...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>they presume their audience wo n't sit still ...</td>\n",
              "      <td>presume audience sit still sociology lesson ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>this is a visually stunning rumination on lov...</td>\n",
              "      <td>visually stunning rumination love memory histo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>jonathan parker 's bartleby should have been ...</td>\n",
              "      <td>jonathan parker bartleby end modern office ano...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01bcc365-b079-48de-9471-9c4bf696e26b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-01bcc365-b079-48de-9471-9c4bf696e26b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-01bcc365-b079-48de-9471-9c4bf696e26b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8dd4577a-2ad6-4b91-8f96-5242f57c9681\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8dd4577a-2ad6-4b91-8f96-5242f57c9681')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8dd4577a-2ad6-4b91-8f96-5242f57c9681 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# Downloading NLTK resources\n",
        "nltk.download()\n",
        "\n",
        "# Initializing lemmatizer and stemmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Function to preprocess a sentence\n",
        "def preprocess_text(sentence):\n",
        "    # Converting the sentence to lowercase\n",
        "    sentence_text = str(sentence).lower()\n",
        "\n",
        "    # Removing '{html}' from the sentence\n",
        "    sentence_text = sentence_text.replace('{html}', \"\")\n",
        "\n",
        "    # Removing HTML tags\n",
        "    cleaner_regex = re.compile('<.*?>')\n",
        "    sentence_text = re.sub(cleaner_regex, '', sentence_text)\n",
        "\n",
        "    # Removing URLs\n",
        "    removed_url = re.sub(r'http\\S+', '', sentence_text)\n",
        "\n",
        "    # Removing numbers\n",
        "    removed_numbers = re.sub('[0-9]+', '', removed_url)\n",
        "\n",
        "    # Tokenizing the sentence\n",
        "    word_tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    word_tokens = word_tokenizer.tokenize(removed_numbers)\n",
        "\n",
        "    # Removing stopwords and filtering out short words\n",
        "    filtered_words = [w for w in word_tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "\n",
        "    # Applying stemming\n",
        "    stemmed_words = [stemmer.stem(w) for w in filtered_words]\n",
        "\n",
        "    # Applying lemmatization\n",
        "    lemmatized_words = [lemmatizer.lemmatize(w) for w in stemmed_words]\n",
        "\n",
        "    # Joining the filtered words into a processed text\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "# Applying the preprocessing function to the 'Text' column and creating a new 'processedText' column\n",
        "dataset['processedText'] = dataset['Text'].map(lambda s: preprocess_text(s))\n",
        "\n",
        "# Displaying the first few rows of the dataset with the processed text\n",
        "dataset.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ae9KuUdKBaqm",
        "outputId": "d7abbd5f-f604-4e28-c080-622780dfa7d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Sentiment                                               Text\n",
              "0         0     no movement , no yuks , not much of anything .\n",
              "1         0   a gob of drivel so sickly sweet , even the ea...\n",
              "2         0   gangs of new york is an unapologetic mess , w...\n",
              "3         0   we never really feel involved with the story ...\n",
              "4         1            this is one of polanski 's best films ."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dea86068-cf16-4e2e-b800-64e1f97f0f85\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>a gob of drivel so sickly sweet , even the ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>gangs of new york is an unapologetic mess , w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>we never really feel involved with the story ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dea86068-cf16-4e2e-b800-64e1f97f0f85')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dea86068-cf16-4e2e-b800-64e1f97f0f85 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dea86068-cf16-4e2e-b800-64e1f97f0f85');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8814b4a-50e2-44ef-bad8-fc834a93fd0e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8814b4a-50e2-44ef-bad8-fc834a93fd0e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8814b4a-50e2-44ef-bad8-fc834a93fd0e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Opening and reading the contents of the \"stsa-test.txt\" file\n",
        "with open(\"stsa-test.txt\") as test_txt_file:\n",
        "    lines_test = [line.rstrip('\\n') for line in test_txt_file]\n",
        "\n",
        "# Separating sentiment labels and text content from each line in the test file\n",
        "sentiments_test = []\n",
        "texts_test = []\n",
        "\n",
        "for line_test in lines_test:\n",
        "    # Extracting sentiment label and text content from each line in the test file\n",
        "    sentiment_test = line_test[0]\n",
        "    text_content_test = line_test[1:]\n",
        "\n",
        "    # Appending sentiment label and text content to their respective lists\n",
        "    sentiments_test.append(sentiment_test)\n",
        "    texts_test.append(text_content_test)\n",
        "\n",
        "# Creating a DataFrame from the lists of sentiment labels and text content for the test dataset\n",
        "dataset_test = pd.DataFrame(list(zip(sentiments_test, texts_test)), columns=['Sentiment', 'Text'])\n",
        "dataset_test.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "JvZSNCieBaqm",
        "outputId": "e25fbe8c-bffc-4717-be5d-909f929c6609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Sentiment                                               Text  \\\n",
              "0         0     no movement , no yuks , not much of anything .   \n",
              "1         0   a gob of drivel so sickly sweet , even the ea...   \n",
              "2         0   gangs of new york is an unapologetic mess , w...   \n",
              "3         0   we never really feel involved with the story ...   \n",
              "4         1            this is one of polanski 's best films .   \n",
              "\n",
              "                                       processedText  \n",
              "0                        movement yuks much anything  \n",
              "1  gob drivel sickly sweet even eager consumers m...  \n",
              "2  gangs new york unapologetic mess whose saving ...  \n",
              "3  never really feel involved story ideas remain ...  \n",
              "4                            one polanski best films  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9625ea84-170f-41e0-aaab-24519e4dbde1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text</th>\n",
              "      <th>processedText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>movement yuks much anything</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>a gob of drivel so sickly sweet , even the ea...</td>\n",
              "      <td>gob drivel sickly sweet even eager consumers m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>gangs of new york is an unapologetic mess , w...</td>\n",
              "      <td>gangs new york unapologetic mess whose saving ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>we never really feel involved with the story ...</td>\n",
              "      <td>never really feel involved story ideas remain ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>one polanski best films</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9625ea84-170f-41e0-aaab-24519e4dbde1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9625ea84-170f-41e0-aaab-24519e4dbde1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9625ea84-170f-41e0-aaab-24519e4dbde1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ada7c8af-c8b1-45fd-b8a0-fd9841fffe55\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ada7c8af-c8b1-45fd-b8a0-fd9841fffe55')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ada7c8af-c8b1-45fd-b8a0-fd9841fffe55 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download()\n",
        "\n",
        "# Initializing lemmatizer and stemmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Function to preprocess a sentence\n",
        "def preprocess_text(sentence):\n",
        "    # Converting the sentence to lowercase\n",
        "    sentence = str(sentence).lower()\n",
        "\n",
        "    # Removing '{html}' from the sentence\n",
        "    sentence = sentence.replace('{html}', \"\")\n",
        "\n",
        "    # Removing HTML tags\n",
        "    cleaner_regex = re.compile('<.*?>')\n",
        "    sentence = re.sub(cleaner_regex, '', sentence)\n",
        "\n",
        "    # Removing URLs\n",
        "    removed_url = re.sub(r'http\\S+', '', sentence)\n",
        "\n",
        "    # Removing numbers\n",
        "    removed_numbers = re.sub('[0-9]+', '', removed_url)\n",
        "\n",
        "    # Tokenizing the sentence\n",
        "    word_tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = word_tokenizer.tokenize(removed_numbers)\n",
        "\n",
        "    # Removing stopwords and filtering out short words\n",
        "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "\n",
        "    # Applying stemming\n",
        "    stemmed_words = [stemmer.stem(w) for w in filtered_words]\n",
        "\n",
        "    # Applying lemmatization\n",
        "    lemmatized_words = [lemmatizer.lemmatize(w) for w in stemmed_words]\n",
        "\n",
        "    # Joining the filtered words into a clean text\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "# Applying the preprocessing function to the 'Text' column and creating a new 'cleanText' column for the test dataset\n",
        "dataset_test['processedText'] = dataset_test['Text'].map(lambda s: preprocess_text(s))\n",
        "\n",
        "# Displaying the first few rows of the test dataset with the cleaned text\n",
        "dataset_test.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sK9P-X-TBaqn"
      },
      "outputs": [],
      "source": [
        "# Import the TfidfVectorizer from sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Creating a TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase=False, analyzer='word')\n",
        "\n",
        "# Transforming the training dataset text into TF-IDF features\n",
        "train_tfidf_features = tfidf_vectorizer.fit_transform(dataset[\"processedText\"]).toarray()\n",
        "\n",
        "# Transforming the test dataset text into TF-IDF features\n",
        "test_tfidf_features = tfidf_vectorizer.transform(dataset_test[\"processedText\"]).toarray()\n",
        "\n",
        "# Preparing the test dataset features and labels\n",
        "x_test = test_tfidf_features\n",
        "y_test = dataset_test[\"Sentiment\"]\n",
        "\n",
        "# Data partitioning\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the training dataset into training and validation sets\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    train_tfidf_features, dataset[\"Sentiment\"], test_size=0.2, random_state=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQHYf70kBaqn",
        "outputId": "c315cf74-7996-42e1-b190-3680cfa23616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set accuracy for the Naive Bayes model: 77.31%\n",
            "Validation set precision for the Naive Bayes model: 80.92%\n",
            "Validation set recall for the Naive Bayes model: 68.98%\n",
            "Validation set F1 score for the Naive Bayes model: 77.13%\n"
          ]
        }
      ],
      "source": [
        "# Multinomial Naive Bayes Classifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Creating an instance of the Multinomial Naive Bayes classifier\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "\n",
        "# Training the model on the training data\n",
        "naive_bayes_model = naive_bayes_classifier.fit(x_train, y_train)\n",
        "\n",
        "# Making predictions on the validation set\n",
        "alternative_predictions_validation = naive_bayes_classifier.predict(x_valid)\n",
        "\n",
        "# Evaluating the performance of the Naive Bayes model on the validation set\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Calculating and printing accuracy\n",
        "accuracy = accuracy_score(y_valid, alternative_predictions_validation)\n",
        "print(\"Validation set accuracy for the Naive Bayes model: {:.2%}\".format(accuracy))\n",
        "\n",
        "# Calculating and printing precision\n",
        "precision = precision_score(y_valid, alternative_predictions_validation, pos_label='0')\n",
        "print(\"Validation set precision for the Naive Bayes model: {:.2%}\".format(precision))\n",
        "\n",
        "# Calculating and printing recall\n",
        "recall = recall_score(y_valid, alternative_predictions_validation, pos_label='0')\n",
        "print(\"Validation set recall for the Naive Bayes model: {:.2%}\".format(recall))\n",
        "\n",
        "# Calculating and printing F1 score\n",
        "f1 = f1_score(y_valid, alternative_predictions_validation, average='weighted')\n",
        "print(\"Validation set F1 score for the Naive Bayes model: {:.2%}\".format(f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z68ngUp5Baqo",
        "outputId": "7be23230-2956-41f3-fbe4-44d22eeed98a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for the Naive Bayes model on the validation set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.69      0.74       664\n",
            "           1       0.75      0.85      0.80       720\n",
            "\n",
            "    accuracy                           0.77      1384\n",
            "   macro avg       0.78      0.77      0.77      1384\n",
            "weighted avg       0.78      0.77      0.77      1384\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Classification Report\n",
        "from sklearn.metrics import classification_report as clf_report\n",
        "\n",
        "# Generating a classification report for the Naive Bayes model on the validation set\n",
        "classification_report_naive_validation = clf_report(y_valid, alternative_predictions_validation)\n",
        "print(\"Classification Report for the Naive Bayes model on the validation set:\\n\", classification_report_naive_validation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47yD6KMyBaqo",
        "outputId": "64f9560d-eae4-456c-fbc4-5bfa70a1d8f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean 10-fold cross-validation score for the Naive Bayes model on the training set: 77%\n"
          ]
        }
      ],
      "source": [
        "#Cross-Validation Score\n",
        "from sklearn.model_selection import cross_val_score as cv_score\n",
        "\n",
        "# Creating an instance of the Naive Bayes classifier for cross-validation\n",
        "naive_bayes_classifier_cv = MultinomialNB()\n",
        "\n",
        "# Calculating 10-fold cross-validation scores for the Naive Bayes model on the training set\n",
        "naive_accuracies_validation_cv = cv_score(estimator=naive_bayes_classifier_cv, X=x_train, y=y_train, cv=10)\n",
        "\n",
        "# Printing the mean cross-validation score\n",
        "print(f\"Mean 10-fold cross-validation score for the Naive Bayes model on the training set: {round(naive_accuracies_validation_cv.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHAQxxrCBaqp",
        "outputId": "08f7b1d3-1ea5-4d48-c4aa-58984f1bf466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy for the Naive Bayes model: 79.08%\n",
            "Test set precision for the Naive Bayes model: 85.54%\n",
            "Test set recall for the Naive Bayes model: 70.07%\n",
            "Test set F1 score for the Naive Bayes model: 77.03%\n"
          ]
        }
      ],
      "source": [
        "# Making predictions on the test set using the trained Naive Bayes classifier\n",
        "predictions_test_set = naive_bayes_classifier.predict(x_test)\n",
        "\n",
        "# Evaluating the performance of the Naive Bayes model on the test set\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculating and printing accuracy on the test set\n",
        "test_set_accuracy = accuracy_score(y_test, predictions_test_set)\n",
        "print(\"Test set accuracy for the Naive Bayes model: {:.2%}\".format(test_set_accuracy))\n",
        "\n",
        "# Calculating and printing precision on the test set\n",
        "test_set_precision = precision_score(y_test, predictions_test_set, pos_label='0')\n",
        "print(\"Test set precision for the Naive Bayes model: {:.2%}\".format(test_set_precision))\n",
        "\n",
        "# Calculating and printing recall on the test set\n",
        "test_set_recall = recall_score(y_test, predictions_test_set, pos_label='0')\n",
        "print(\"Test set recall for the Naive Bayes model: {:.2%}\".format(test_set_recall))\n",
        "\n",
        "# Calculating and printing F1 score on the test set\n",
        "test_set_f1 = f1_score(y_test, predictions_test_set, pos_label='0')\n",
        "print(\"Test set F1 score for the Naive Bayes model: {:.2%}\".format(test_set_f1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X38roCE7Baqp",
        "outputId": "9d29e02e-2542-472d-bbed-059ae5b94691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for the Naive Bayes model on the test set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.70      0.77       912\n",
            "           1       0.75      0.88      0.81       909\n",
            "\n",
            "    accuracy                           0.79      1821\n",
            "   macro avg       0.80      0.79      0.79      1821\n",
            "weighted avg       0.80      0.79      0.79      1821\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generating a classification report for the Naive Bayes model on the test set\n",
        "classification_report_naive_test = clf_report(y_test, predictions_test_set)\n",
        "print(\"Classification Report for the Naive Bayes model on the test set:\\n\", classification_report_naive_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eyC9GhXBaqp",
        "outputId": "ace94287-53d3-470d-efe3-3354249f3b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean 10-fold cross-validation score for the Naive Bayes model on the test set: 73%\n"
          ]
        }
      ],
      "source": [
        "# Calculate 10-fold cross-validation scores for the Naive Bayes model on the test set\n",
        "naive_accuracies_test_cv = cv_score(estimator=naive_bayes_classifier, X=x_test, y=y_test, cv=10)\n",
        "\n",
        "# Print the mean cross-validation score on the test set\n",
        "print(f\"Mean 10-fold cross-validation score for the Naive Bayes model on the test set: {round(naive_accuracies_test_cv.mean()*100)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "DqBFH-4zkMbt",
        "outputId": "fc86284e-eb41-470d-8ef1-1a05c02d5ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f4c1cac2-483a-4ca3-9806-2446b3e2da3e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f4c1cac2-483a-4ca3-9806-2446b3e2da3e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving stsa-test.txt to stsa-test.txt\n",
            "Saving stsa-train.txt to stsa-train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import svm\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Suppressing warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Function to preprocess a sentence\n",
        "def preprocess_text(sentence):\n",
        "    # Converting the sentence to lowercase\n",
        "    sentence_text = str(sentence).lower()\n",
        "\n",
        "    # Removing '{html}' from the sentence\n",
        "    sentence_text = sentence_text.replace('{html}', \"\")\n",
        "\n",
        "    # Removing HTML tags\n",
        "    cleaner_regex = re.compile('<.*?>')\n",
        "    sentence_text = re.sub(cleaner_regex, '', sentence_text)\n",
        "\n",
        "    # Removing URLs\n",
        "    removed_url = re.sub(r'http\\S+', '', sentence_text)\n",
        "\n",
        "    # Removing numbers\n",
        "    removed_numbers = re.sub('[0-9]+', '', removed_url)\n",
        "\n",
        "    # Tokenizing the sentence\n",
        "    word_tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    word_tokens = word_tokenizer.tokenize(removed_numbers)\n",
        "\n",
        "    # Removing stopwords and filtering out short words\n",
        "    filtered_words = [w for w in word_tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "\n",
        "    # Applying stemming\n",
        "    stemmed_words = [stemmer.stem(w) for w in filtered_words]\n",
        "\n",
        "    # Applying lemmatization\n",
        "    lemmatized_words = [lemmatizer.lemmatize(w) for w in stemmed_words]\n",
        "\n",
        "    # Joining the filtered words into a processed text\n",
        "    return \" \".join(filtered_words)\n"
      ],
      "metadata": {
        "id": "jGZezmX6mxRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the preprocessing function to the 'Text' column and creating a new 'processedText' column\n",
        "dataset['processedText'] = dataset['Text'].map(lambda s: preprocess_text(s))\n"
      ],
      "metadata": {
        "id": "pLz1vmMjoMFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase=False, analyzer='word')\n",
        "\n",
        "# Transforming the training dataset text into TF-IDF features\n",
        "train_tfidf_features = tfidf_vectorizer.fit_transform(dataset[\"processedText\"]).toarray()\n"
      ],
      "metadata": {
        "id": "ACU2W6e1ntFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the training dataset into training and validation sets\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    train_tfidf_features, dataset[\"Sentiment\"], test_size=0.2, random_state=2)\n"
      ],
      "metadata": {
        "id": "ZH_-llGrnc9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwGuDyNJBaqq",
        "outputId": "5651b275-bceb-4ee0-bae7-17de96e565cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the SVM model on validation set: 77.31%\n",
            "Precision of the SVM model on validation set: 77.69%\n",
            "Recall of the SVM model on validation set: 73.95%\n",
            "F1 Score of the SVM model on validation set: 75.77%\n"
          ]
        }
      ],
      "source": [
        "# Import the SVM classifier from scikit-learn\n",
        "from sklearn import svm\n",
        "\n",
        "# Create an instance of the SVM classifier\n",
        "classifier_svm = svm.SVC()\n",
        "\n",
        "# Train the SVM model on the training data\n",
        "model_svm = classifier_svm.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set using the SVM model\n",
        "svm_predictions_validation_set = classifier_svm.predict(x_valid)\n",
        "\n",
        "# Print accuracy of the SVM model on the validation set\n",
        "print(\"Accuracy of the SVM model on validation set: {:.2%}\".format(accuracy_score(y_valid, svm_predictions_validation_set)))\n",
        "\n",
        "# Print precision of the SVM model on the validation set\n",
        "print(\"Precision of the SVM model on validation set: {:.2%}\".format(precision_score(y_valid, svm_predictions_validation_set, pos_label='0')))\n",
        "\n",
        "# Print recall of the SVM model on the validation set\n",
        "print(\"Recall of the SVM model on validation set: {:.2%}\".format(recall_score(y_valid, svm_predictions_validation_set, pos_label='0')))\n",
        "\n",
        "# Print F1 score of the SVM model on the validation set\n",
        "print(\"F1 Score of the SVM model on validation set: {:.2%}\".format(f1_score(y_valid, svm_predictions_validation_set, pos_label='0')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAAhX7baBaqq",
        "outputId": "1a2c118d-3312-4aa8-fdaa-76904d65ef7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for the SVM model on the validation set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.74      0.76       664\n",
            "           1       0.77      0.80      0.79       720\n",
            "\n",
            "    accuracy                           0.77      1384\n",
            "   macro avg       0.77      0.77      0.77      1384\n",
            "weighted avg       0.77      0.77      0.77      1384\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importing the classification_report function from sklearn.metrics\n",
        "from sklearn.metrics import classification_report as clf_report_svm\n",
        "\n",
        "# Generating a classification report for the SVM model on the validation set\n",
        "classification_report_svm_validation = clf_report_svm(y_valid, svm_predictions_validation_set)\n",
        "\n",
        "# Printing the classification report\n",
        "print(\"Classification Report for the SVM model on the validation set:\\n\", classification_report_svm_validation)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing cross_val_score from sklearn.model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# Calculating 10-fold cross-validation scores for the SVM model on the training set\n",
        "svm_accuracies_validation_cv = cross_val_score(estimator=classifier_svm, X=x_train, y=y_train, cv=10)\n",
        "\n",
        "# Printing the mean cross-validation score on the training set\n",
        "print(f\"Mean 10-fold cross-validation score for the SVM model on the training set: {round(svm_accuracies_validation_cv.mean()*100)}%\")\n"
      ],
      "metadata": {
        "id": "eYkO9bYCZCti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test set using the SVM model\n",
        "svm_test_set_predictions = svm.predict(x_test)\n",
        "\n",
        "# Evaluating the performance of the SVM model on the test set\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculating and printing accuracy on the test set\n",
        "svm_test_set_accuracy = accuracy_score(y_test, svm_test_set_predictions)\n",
        "print(\"Test set accuracy for the SVM model: {:.2%}\".format(svm_test_set_accuracy))\n",
        "\n",
        "# Calculating and printing precision on the test set\n",
        "svm_test_set_precision = precision_score(y_test, svm_test_set_predictions, pos_label='0')\n",
        "print(\"Precision of the SVM model on the test set: {:.2%}\".format(svm_test_set_precision))\n",
        "\n",
        "# Calculating and printing recall on the test set\n",
        "svm_test_set_recall = recall_score(y_test, svm_test_set_predictions, pos_label='0')\n",
        "print(\"Recall of the SVM model on the test set: {:.2%}\".format(svm_test_set_recall))\n",
        "\n",
        "# Calculating and printing F1 score on the test set\n",
        "svm_test_set_f1 = f1_score(y_test, svm_test_set_predictions, pos_label='0')\n",
        "print(\"F1 Score of the SVM model on the test set: {:.2%}\".format(svm_test_set_f1))\n"
      ],
      "metadata": {
        "id": "ZAtmIG64iBX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8MUWZHcBaqq"
      },
      "outputs": [],
      "source": [
        "# Importing the classification_report function from sklearn.metrics\n",
        "from sklearn.metrics import classification_report as clf_report_svm\n",
        "\n",
        "# Generating a classification report for the SVM model on the test set\n",
        "classification_report_svm_test = clf_report_svm(y_test, svm_test_set_predictions)\n",
        "\n",
        "# Printing the classification report\n",
        "print(\"Classification Report for the SVM model on the test set:\\n\", classification_report_svm_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "75309f10-d0b6-49e6-cd9b-401941f38244",
        "id": "W9TEWzQ-7wzy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-915d6026-b373-49e9-ab2d-970a52eb002a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-915d6026-b373-49e9-ab2d-970a52eb002a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving stsa-test.txt to stsa-test (11).txt\n",
            "Saving stsa-train.txt to stsa-train (11).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import svm\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Suppressing warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Function to preprocess a sentence\n",
        "def preprocess_text(sentence):\n",
        "    # Converting the sentence to lowercase\n",
        "    sentence_text = str(sentence).lower()\n",
        "\n",
        "    # Removing '{html}' from the sentence\n",
        "    sentence_text = sentence_text.replace('{html}', \"\")\n",
        "\n",
        "    # Removing HTML tags\n",
        "    cleaner_regex = re.compile('<.*?>')\n",
        "    sentence_text = re.sub(cleaner_regex, '', sentence_text)\n",
        "\n",
        "    # Removing URLs\n",
        "    removed_url = re.sub(r'http\\S+', '', sentence_text)\n",
        "\n",
        "    # Removing numbers\n",
        "    removed_numbers = re.sub('[0-9]+', '', removed_url)\n",
        "\n",
        "    # Tokenizing the sentence\n",
        "    word_tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    word_tokens = word_tokenizer.tokenize(removed_numbers)\n",
        "\n",
        "    # Removing stopwords and filtering out short words\n",
        "    filtered_words = [w for w in word_tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "\n",
        "    # Applying stemming\n",
        "    stemmed_words = [stemmer.stem(w) for w in filtered_words]\n",
        "\n",
        "    # Applying lemmatization\n",
        "    lemmatized_words = [lemmatizer.lemmatize(w) for w in stemmed_words]\n",
        "\n",
        "    # Joining the filtered words into a processed text\n",
        "    return \" \".join(filtered_words)\n"
      ],
      "metadata": {
        "id": "YLBuWfO-73Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the preprocessing function to the 'Text' column and creating a new 'processedText' column\n",
        "dataset['processedText'] = dataset['Text'].map(lambda s: preprocess_text(s))\n"
      ],
      "metadata": {
        "id": "noe5IpYI7-yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase=False, analyzer='word')\n",
        "\n",
        "# Transforming the training dataset text into TF-IDF features\n",
        "train_tfidf_features = tfidf_vectorizer.fit_transform(dataset[\"processedText\"]).toarray()\n"
      ],
      "metadata": {
        "id": "xniMfSXB8EKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the training dataset into training and validation sets\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    train_tfidf_features, dataset[\"Sentiment\"], test_size=0.2, random_state=2)\n"
      ],
      "metadata": {
        "id": "k7xQ8TYP8KAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trr1iwNCBaqq",
        "outputId": "7d81166e-1ae8-4f0b-c6e8-5e9414fd8955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set accuracy for the KNN model: 66.26%\n",
            "Precision of the KNN model on the validation set: 59.92%\n",
            "Recall of the KNN model on the validation set: 89.61%\n",
            "F1 Score of the KNN model on the validation set: 71.82%\n"
          ]
        }
      ],
      "source": [
        "# K-Nearest Neighbors (KNN)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Creating an instance of the KNN classifier with 15 neighbors\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=15)\n",
        "\n",
        "# Training the KNN model on the training data\n",
        "knn_model = knn_classifier.fit(x_train, y_train)\n",
        "\n",
        "# Making predictions on the validation set using the KNN model\n",
        "knn_predictions_validation = knn_classifier.predict(x_valid)\n",
        "\n",
        "# Evaluating the performance of the KNN model on the validation set\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculating and printing accuracy on the validation set\n",
        "knn_validation_accuracy = accuracy_score(y_valid, knn_predictions_validation)\n",
        "print(\"Validation set accuracy for the KNN model: {:.2%}\".format(knn_validation_accuracy))\n",
        "\n",
        "# Calculating and printing precision on the validation set\n",
        "knn_validation_precision = precision_score(y_valid, knn_predictions_validation, pos_label='0')\n",
        "print(\"Precision of the KNN model on the validation set: {:.2%}\".format(knn_validation_precision))\n",
        "\n",
        "# Calculating and printing recall on the validation set\n",
        "knn_validation_recall = recall_score(y_valid, knn_predictions_validation, pos_label='0')\n",
        "print(\"Recall of the KNN model on the validation set: {:.2%}\".format(knn_validation_recall))\n",
        "\n",
        "# Calculating and printing F1 score on the validation set\n",
        "knn_validation_f1 = f1_score(y_valid, knn_predictions_validation, pos_label='0')\n",
        "print(\"F1 Score of the KNN model on the validation set: {:.2%}\".format(knn_validation_f1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30z4w1DABaqr",
        "outputId": "87b0b7c8-043e-4147-ae89-3207e2bc09f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for KNN on the validation set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.90      0.72       664\n",
            "           1       0.82      0.45      0.58       720\n",
            "\n",
            "    accuracy                           0.66      1384\n",
            "   macro avg       0.71      0.67      0.65      1384\n",
            "weighted avg       0.72      0.66      0.65      1384\n",
            "\n"
          ]
        }
      ],
      "source": [
        "knn_predictions_validation_set = knn_classifier.predict(x_valid)\n",
        "\n",
        "# Import the classification_report function from scikit-learn metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate a classification report for KNN predictions on the validation set\n",
        "classification_report_knn_validation = classification_report(y_valid, knn_predictions_validation_set)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report for KNN on the validation set:\")\n",
        "print(classification_report_knn_validation)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Create an instance of the KNN classifier\n",
        "classifier_knn = KNeighborsClassifier(n_neighbors=15)\n",
        "\n",
        "# Train the KNN model on the training data\n",
        "classifier_knn.fit(x_train, y_train)\n",
        "\n",
        "# Perform 10-fold cross-validation for the KNN model on the training set\n",
        "knn_cross_val_scores = cross_val_score(estimator=classifier_knn, X=x_train, y=y_train, cv=10)\n",
        "\n",
        "# Calculate the mean accuracy across all folds and round it to two decimal places\n",
        "mean_cross_val_accuracy = round(knn_cross_val_scores.mean() * 100, 2)\n",
        "\n",
        "# Print the mean 10-fold cross-validation score for the KNN model on the training set\n",
        "print(f\"KNN Model 10-fold cross-validation score on the training set: {mean_cross_val_accuracy}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTsdvrqu_LZ8",
        "outputId": "8b63f389-c765-4ff3-bb75-99bbc2fda2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Model 10-fold cross-validation score on the training set: 67.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set using the KNN classifier\n",
        "knn_predictions_test_set = classifier_knn.predict(x_test)\n",
        "\n",
        "# Evaluate the performance of the KNN model on the test set\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate and print accuracy on the test set\n",
        "knn_test_set_accuracy = accuracy_score(y_test, knn_predictions_test_set)\n",
        "print(\"Accuracy of the KNN model on the test set: {:.2%}\".format(knn_test_set_accuracy))\n",
        "\n",
        "# Calculate and print precision on the test set\n",
        "knn_test_set_precision = precision_score(y_test, knn_predictions_test_set, pos_label='0')\n",
        "print(\"Precision of the KNN model on the test set: {:.2%}\".format(knn_test_set_precision))\n",
        "\n",
        "# Calculate and print recall on the test set\n",
        "knn_test_set_recall = recall_score(y_test, knn_predictions_test_set, pos_label='0')\n",
        "print(\"Recall of the KNN model on the test set: {:.2%}\".format(knn_test_set_recall))\n",
        "\n",
        "# Calculate and print F1 score on the test set\n",
        "knn_test_set_f1 = f1_score(y_test, knn_predictions_test_set, pos_label='0')\n",
        "print(\"F1 Score of the KNN model on the test set: {:.2%}\".format(knn_test_set_f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uQHHpEf8MUU",
        "outputId": "e004a8e2-31a1-4d33-c42a-bf7dad2be51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the KNN model on the test set: 68.26%\n",
            "Precision of the KNN model on the test set: 62.75%\n",
            "Recall of the KNN model on the test set: 90.13%\n",
            "F1 Score of the KNN model on the test set: 73.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a classification report for KNN predictions on the test set\n",
        "classification_report_knn_test = classification_report(y_test, knn_predictions_test_set)\n",
        "\n",
        "# Print the classification report for the KNN model on the test set\n",
        "print(\"Classification Report for KNN on the test set:\")\n",
        "print(classification_report_knn_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12ViH9cW9OY3",
        "outputId": "0b99040d-b760-41ae-8cc1-70d7c0e316f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for KNN on the test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.90      0.74       912\n",
            "           1       0.82      0.46      0.59       909\n",
            "\n",
            "    accuracy                           0.68      1821\n",
            "   macro avg       0.73      0.68      0.67      1821\n",
            "weighted avg       0.73      0.68      0.67      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the cross_val_score function from scikit-learn model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform 10-fold cross-validation for the KNN model on the test set\n",
        "knn_cross_val_scores_test = cross_val_score(estimator=classifier_knn, X=x_test, y=y_test, cv=10)\n",
        "\n",
        "# Calculate the mean accuracy across all folds and round it to two decimal places\n",
        "mean_cross_val_accuracy_test = round(knn_cross_val_scores_test.mean() * 100, 2)\n",
        "\n",
        "# Print the mean 10-fold cross-validation score for the KNN model on the test set\n",
        "print(f\"KNN Model 10-fold cross-validation score on the testing set: {mean_cross_val_accuracy_test}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA74K87W9Ob0",
        "outputId": "a85f3704-588c-4df8-9d38-8d04cec32acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Model 10-fold cross-validation score on the testing set: 62.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "abveCUq5Baqr",
        "outputId": "76e3a1c0-637e-4350-de0b-de8fd988b8cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4fae82c8-1078-4092-8ac5-a332dcb961dc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4fae82c8-1078-4092-8ac5-a332dcb961dc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving stsa-test.txt to stsa-test (13).txt\n",
            "Saving stsa-train.txt to stsa-train (13).txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import svm\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Suppressing warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Function to preprocess a sentence\n",
        "def preprocess_text(sentence):\n",
        "    # Converting the sentence to lowercase\n",
        "    sentence_text = str(sentence).lower()\n",
        "\n",
        "    # Removing '{html}' from the sentence\n",
        "    sentence_text = sentence_text.replace('{html}', \"\")\n",
        "\n",
        "    # Removing HTML tags\n",
        "    cleaner_regex = re.compile('<.*?>')\n",
        "    sentence_text = re.sub(cleaner_regex, '', sentence_text)\n",
        "\n",
        "    # Removing URLs\n",
        "    removed_url = re.sub(r'http\\S+', '', sentence_text)\n",
        "\n",
        "    # Removing numbers\n",
        "    removed_numbers = re.sub('[0-9]+', '', removed_url)\n",
        "\n",
        "    # Tokenizing the sentence\n",
        "    word_tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    word_tokens = word_tokenizer.tokenize(removed_numbers)\n",
        "\n",
        "    # Removing stopwords and filtering out short words\n",
        "    filtered_words = [w for w in word_tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "\n",
        "    # Applying stemming\n",
        "    stemmed_words = [stemmer.stem(w) for w in filtered_words]\n",
        "\n",
        "    # Applying lemmatization\n",
        "    lemmatized_words = [lemmatizer.lemmatize(w) for w in stemmed_words]\n",
        "\n",
        "    # Joining the filtered words into a processed text\n",
        "    return \" \".join(filtered_words)"
      ],
      "metadata": {
        "id": "-AJFcCpQ_x5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Applying the preprocessing function to the 'Text' column and creating a new 'processedText' column\n",
        "dataset['processedText'] = dataset['Text'].map(lambda s: preprocess_text(s))\n"
      ],
      "metadata": {
        "id": "-u5VZwVy_x7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase=False, analyzer='word')\n"
      ],
      "metadata": {
        "id": "6PbjTdQx_x-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming the training dataset text into TF-IDF features\n",
        "train_tfidf_features = tfidf_vectorizer.fit_transform(dataset[\"processedText\"]).toarray()\n"
      ],
      "metadata": {
        "id": "PqmVl2Ad_yAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the training dataset into training and validation sets\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    train_tfidf_features, dataset[\"Sentiment\"], test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "z3BvwBE2_yDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create an instance of the Decision Tree classifier\n",
        "classifier_decision_tree = DecisionTreeClassifier()\n",
        "\n",
        "# Train the Decision Tree model on the training data\n",
        "model_decision_tree = classifier_decision_tree.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set using the Decision Tree model\n",
        "dt_predictions_validation = classifier_decision_tree.predict(x_valid)\n",
        "\n",
        "# Evaluate the performance of the Decision Tree model on the validation set\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate and print accuracy on the validation set\n",
        "dt_validation_accuracy = accuracy_score(y_valid, dt_predictions_validation)\n",
        "print(\"Validation set accuracy for the Decision Tree model: {:.2%}\".format(dt_validation_accuracy))\n",
        "\n",
        "# Calculate and print precision on the validation set\n",
        "dt_validation_precision = precision_score(y_valid, dt_predictions_validation, pos_label='0')\n",
        "print(\"Precision of the Decision Tree model on the validation set: {:.2%}\".format(dt_validation_precision))\n",
        "\n",
        "# Calculate and print recall on the validation set\n",
        "dt_validation_recall = recall_score(y_valid, dt_predictions_validation, pos_label='0')\n",
        "print(\"Recall of the Decision Tree model on the validation set: {:.2%}\".format(dt_validation_recall))\n",
        "\n",
        "# Calculate and print F1 score on the validation set\n",
        "dt_validation_f1 = f1_score(y_valid, dt_predictions_validation, pos_label='0')\n",
        "print(\"F1 Score of the Decision Tree model on the validation set: {:.2%}\".format(dt_validation_f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDqPt5r2_yF7",
        "outputId": "f2b850bb-1120-4759-c780-5bdddfcb837f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set accuracy for the Decision Tree model: 64.52%\n",
            "Precision of the Decision Tree model on the validation set: 62.06%\n",
            "Recall of the Decision Tree model on the validation set: 67.02%\n",
            "F1 Score of the Decision Tree model on the validation set: 64.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the classification_report function from scikit-learn metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate a classification report for Decision Tree predictions on the validation set\n",
        "classification_report_dt_validation = classification_report(y_valid, dt_predictions_validation)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report for Decision Tree on the validation set:\")\n",
        "print(classification_report_dt_validation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3WfXYfa_yIh",
        "outputId": "4cd3adc4-d3bf-482e-ff07-d8f520b7860b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Decision Tree on the validation set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.67      0.64       664\n",
            "           1       0.67      0.62      0.65       720\n",
            "\n",
            "    accuracy                           0.65      1384\n",
            "   macro avg       0.65      0.65      0.65      1384\n",
            "weighted avg       0.65      0.65      0.65      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create an instance of the Decision Tree classifier\n",
        "classifier_dt = DecisionTreeClassifier()\n",
        "\n",
        "# Train the Decision Tree model on the training data\n",
        "model_dt = classifier_dt.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "hrihi9yrDdMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the cross_val_score function from scikit-learn model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform 10-fold cross-validation for the Decision Tree model on the training set\n",
        "dt_cross_val_scores = cross_val_score(estimator=classifier_dt, X=x_train, y=y_train, cv=10)\n",
        "\n",
        "# Calculate the mean accuracy across all folds and round it to two decimal places\n",
        "mean_cross_val_accuracy_dt = round(dt_cross_val_scores.mean() * 100, 2)\n",
        "\n",
        "# Print the mean 10-fold cross-validation score for the Decision Tree model on the training set\n",
        "print(f\"Decision Tree Classifier Model 10-fold cross-validation score on the training set: {mean_cross_val_accuracy_dt}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIcfJLBUA6d4",
        "outputId": "61bd0b30-9962-4ccf-fdd2-e3851670d03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier Model 10-fold cross-validation score on the training set: 64.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set using the Decision Tree classifier\n",
        "dt_predictions_test_set = classifier_dt.predict(x_test)\n",
        "\n",
        "# Evaluate the performance of the Decision Tree model on the test set\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate and print accuracy on the test set\n",
        "dt_test_set_accuracy = accuracy_score(y_test, dt_predictions_test_set)\n",
        "print(\"Accuracy of the Decision Tree Classifier model on the test set: {:.2%}\".format(dt_test_set_accuracy))\n",
        "\n",
        "# Calculate and print precision on the test set\n",
        "dt_test_set_precision = precision_score(y_test, dt_predictions_test_set, pos_label='0')\n",
        "print(\"Precision of the Decision Tree Classifier model on the test set: {:.2%}\".format(dt_test_set_precision))\n",
        "\n",
        "# Calculate and print recall on the test set\n",
        "dt_test_set_recall = recall_score(y_test, dt_predictions_test_set, pos_label='0')\n",
        "print(\"Recall of the Decision Tree Classifier model on the test set: {:.2%}\".format(dt_test_set_recall))\n",
        "\n",
        "# Calculate and print F1 score on the test set\n",
        "dt_test_set_f1 = f1_score(y_test, dt_predictions_test_set, pos_label='0')\n",
        "print(\"F1 Score of the Decision Tree Classifier model on the test set: {:.2%}\".format(dt_test_set_f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCimK66tA6mV",
        "outputId": "09f72999-50f7-4645-b775-9fca0a8a91f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Decision Tree Classifier model on the test set: 65.68%\n",
            "Precision of the Decision Tree Classifier model on the test set: 65.19%\n",
            "Recall of the Decision Tree Classifier model on the test set: 67.54%\n",
            "F1 Score of the Decision Tree Classifier model on the test set: 66.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the classification_report function from scikit-learn metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate a classification report for Decision Tree predictions on the test set\n",
        "cr_dt_test = classification_report(y_test, dt_predictions_test_set)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report for Decision Tree on the test set:\")\n",
        "print(cr_dt_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAh5pzorA6o9",
        "outputId": "849d89a0-489d-4a71-82a6-598b89b274cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Decision Tree on the test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.68      0.66       912\n",
            "           1       0.66      0.64      0.65       909\n",
            "\n",
            "    accuracy                           0.66      1821\n",
            "   macro avg       0.66      0.66      0.66      1821\n",
            "weighted avg       0.66      0.66      0.66      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the cross_val_score function from scikit-learn model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform 10-fold cross-validation for the Decision Tree model on the testing set\n",
        "dt_accuracies_test = cross_val_score(estimator=classifier_dt, X=x_test, y=y_test, cv=10)\n",
        "\n",
        "# Calculate the mean accuracy across all folds and round it to two decimal places\n",
        "mean_dt_test_accuracy = round(dt_accuracies_test.mean() * 100, 2)\n",
        "\n",
        "# Print the mean 10-fold cross-validation score for the Decision Tree model on the testing set\n",
        "print(f\"Decision Tree Classifier Model 10-fold cross-validation score on the testing set: {mean_dt_test_accuracy}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKUwg3kO_yLd",
        "outputId": "bc09d26f-9c11-425e-e158-7d3ae8c886a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier Model 10-fold cross-validation score on the testing set: 62.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "2PdZJnax_yOl",
        "outputId": "e01299f1-a376-471a-cf3c-eaae6069a5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0cb66e35-74c3-4201-8f64-9d7c26235acb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0cb66e35-74c3-4201-8f64-9d7c26235acb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving stsa-test.txt to stsa-test (14).txt\n",
            "Saving stsa-train.txt to stsa-train (14).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import svm\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Suppressing warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Function to preprocess a sentence\n",
        "def preprocess_text(sentence):\n",
        "    # Converting the sentence to lowercase\n",
        "    sentence_text = str(sentence).lower()\n",
        "\n",
        "    # Removing '{html}' from the sentence\n",
        "    sentence_text = sentence_text.replace('{html}', \"\")\n",
        "\n",
        "    # Removing HTML tags\n",
        "    cleaner_regex = re.compile('<.*?>')\n",
        "    sentence_text = re.sub(cleaner_regex, '', sentence_text)\n",
        "\n",
        "    # Removing URLs\n",
        "    removed_url = re.sub(r'http\\S+', '', sentence_text)\n",
        "\n",
        "    # Removing numbers\n",
        "    removed_numbers = re.sub('[0-9]+', '', removed_url)\n",
        "\n",
        "    # Tokenizing the sentence\n",
        "    word_tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    word_tokens = word_tokenizer.tokenize(removed_numbers)\n",
        "\n",
        "    # Removing stopwords and filtering out short words\n",
        "    filtered_words = [w for w in word_tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "\n",
        "    # Applying stemming\n",
        "    stemmed_words = [stemmer.stem(w) for w in filtered_words]\n",
        "\n",
        "    # Applying lemmatization\n",
        "    lemmatized_words = [lemmatizer.lemmatize(w) for w in stemmed_words]\n",
        "\n",
        "    # Joining the filtered words into a processed text\n",
        "    return \" \".join(filtered_words)\n"
      ],
      "metadata": {
        "id": "Kxil_WkLBrir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the preprocessing function to the 'Text' column and creating a new 'processedText' column\n",
        "dataset['processedText'] = dataset['Text'].map(lambda s: preprocess_text(s))"
      ],
      "metadata": {
        "id": "2PYULOZEBrmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating a TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase=False, analyzer='word')"
      ],
      "metadata": {
        "id": "D4LRCYWlBron"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming the training dataset text into TF-IDF features\n",
        "train_tfidf_features = tfidf_vectorizer.fit_transform(dataset[\"processedText\"]).toarray()"
      ],
      "metadata": {
        "id": "LvvzTlK8BrrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the training dataset into training and validation sets\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    train_tfidf_features, dataset[\"Sentiment\"], test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "GGGqHeXuBrtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create an instance of the Random Forest classifier\n",
        "classifier_rf = RandomForestClassifier()\n",
        "\n",
        "# Train the Random Forest model on the training data\n",
        "model_rf = classifier_rf.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set using the Random Forest model\n",
        "rf_predictions_validation = classifier_rf.predict(x_valid)\n",
        "\n",
        "# Evaluate the performance of the Random Forest model on the validation set\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate and print accuracy on the validation set\n",
        "rf_validation_accuracy = accuracy_score(y_valid, rf_predictions_validation)\n",
        "print(\"Validation set accuracy for the Random Forest model: {:.2%}\".format(rf_validation_accuracy))\n",
        "\n",
        "# Calculate and print precision on the validation set\n",
        "rf_validation_precision = precision_score(y_valid, rf_predictions_validation, pos_label='0')\n",
        "print(\"Precision of the Random Forest model on the validation set: {:.2%}\".format(rf_validation_precision))\n",
        "\n",
        "# Calculate and print recall on the validation set\n",
        "rf_validation_recall = recall_score(y_valid, rf_predictions_validation, pos_label='0')\n",
        "print(\"Recall of the Random Forest model on the validation set: {:.2%}\".format(rf_validation_recall))\n",
        "\n",
        "# Calculate and print F1 score on the validation set\n",
        "rf_validation_f1 = f1_score(y_valid, rf_predictions_validation, pos_label='0')\n",
        "print(\"F1 Score of the Random Forest model on the validation set: {:.2%}\".format(rf_validation_f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZVv4X-zBnCH",
        "outputId": "732bcb96-0e2a-4bfa-ee96-aaf0b227178b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set accuracy for the Random Forest model: 71.60%\n",
            "Precision of the Random Forest model on the validation set: 68.79%\n",
            "Recall of the Random Forest model on the validation set: 74.70%\n",
            "F1 Score of the Random Forest model on the validation set: 71.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the classification_report function from scikit-learn metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate a classification report for Random Forest predictions on the validation set\n",
        "classification_report_rf_validation = classification_report(y_valid, rf_predictions_validation)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report for Random Forest on the validation set:\")\n",
        "print(classification_report_rf_validation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwGRuWtFEmfH",
        "outputId": "1cd9f228-c546-4956-8ffa-15927230af4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Random Forest on the validation set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.75      0.72       664\n",
            "           1       0.75      0.69      0.72       720\n",
            "\n",
            "    accuracy                           0.72      1384\n",
            "   macro avg       0.72      0.72      0.72      1384\n",
            "weighted avg       0.72      0.72      0.72      1384\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the cross_val_score function from scikit-learn model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform 10-fold cross-validation for the Random Forest model on the training set\n",
        "rf_cross_val_scores = cross_val_score(estimator=classifier_rf, X=x_train, y=y_train, cv=10)\n",
        "\n",
        "# Calculate the mean accuracy across all folds and round it to two decimal places\n",
        "mean_cross_val_accuracy_rf = round(rf_cross_val_scores.mean() * 100, 2)\n",
        "\n",
        "# Print the mean 10-fold cross-validation score for the Random Forest model on the training set\n",
        "print(f\"Random Forest Model 10-fold cross-validation score on the training set: {mean_cross_val_accuracy_rf}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa1UJh5PEmiT",
        "outputId": "293decda-db99-49b2-e11d-c402b55ce9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model 10-fold cross-validation score on the training set: 72.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set using the Random Forest classifier\n",
        "rf_predictions_test_set = classifier_rf.predict(x_test)\n",
        "\n",
        "# Evaluate the performance of the Random Forest model on the test set\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate and print accuracy on the test set\n",
        "rf_test_set_accuracy = accuracy_score(y_test, rf_predictions_test_set)\n",
        "print(\"Accuracy of the Random Forest Classifier model on the test set: {:.2%}\".format(rf_test_set_accuracy))\n",
        "\n",
        "# Calculate and print precision on the test set\n",
        "rf_test_set_precision = precision_score(y_test, rf_predictions_test_set, pos_label='0')\n",
        "print(\"Precision of the Random Forest Classifier model on the test set: {:.2%}\".format(rf_test_set_precision))\n",
        "\n",
        "# Calculate and print recall on the test set\n",
        "rf_test_set_recall = recall_score(y_test, rf_predictions_test_set, pos_label='0')\n",
        "print(\"Recall of the Random Forest Classifier model on the test set: {:.2%}\".format(rf_test_set_recall))\n",
        "\n",
        "# Calculate and print F1 score on the test set\n",
        "rf_test_set_f1 = f1_score(y_test, rf_predictions_test_set, pos_label='0')\n",
        "print(\"F1 Score of the Random Forest Classifier model on the test set: {:.2%}\".format(rf_test_set_f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbIOIsbZE8fR",
        "outputId": "b7b51cb2-8d99-45b8-f1dc-239a933bd60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Random Forest Classifier model on the test set: 72.71%\n",
            "Precision of the Random Forest Classifier model on the test set: 70.90%\n",
            "Recall of the Random Forest Classifier model on the test set: 77.19%\n",
            "F1 Score of the Random Forest Classifier model on the test set: 73.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the classification_report function from scikit-learn metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate a classification report for Random Forest predictions on the test set\n",
        "classification_report_rf_test = classification_report(y_test, rf_predictions_test_set)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report for Random Forest on the test set:\")\n",
        "print(classification_report_rf_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm5lZSobEmm_",
        "outputId": "59fd89e8-5e68-4766-f38e-bebfc1e2c5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Random Forest on the test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.77      0.74       912\n",
            "           1       0.75      0.68      0.71       909\n",
            "\n",
            "    accuracy                           0.73      1821\n",
            "   macro avg       0.73      0.73      0.73      1821\n",
            "weighted avg       0.73      0.73      0.73      1821\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the cross_val_score function from scikit-learn model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform 10-fold cross-validation for the Random Forest model on the testing set\n",
        "rf_cross_val_scores_test = cross_val_score(estimator=classifier_rf, X=x_test, y=y_test, cv=10)\n",
        "\n",
        "# Calculate the mean accuracy across all folds and round it to two decimal places\n",
        "mean_cross_val_accuracy_test = round(rf_cross_val_scores_test.mean() * 100, 2)\n",
        "\n",
        "# Print the mean 10-fold cross-validation score for the Random Forest model on the testing set\n",
        "print(f\"Random Forest Classifier Model 10-fold cross-validation score on the testing set: {mean_cross_val_accuracy_test}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1u9tgMlBnE2",
        "outputId": "471693da-41ac-4364-b32c-d6008481198d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Model 10-fold cross-validation score on the testing set: 65.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJb_UEQuFgkX",
        "outputId": "fefd76bc-ed12-4fcc-c07d-ef2f17707f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Convert string classes to numerical classes for y_train\n",
        "y_train_numeric = y_train.astype(int)\n",
        "\n",
        "# Creating an instance of the XGBoost classifier\n",
        "classifier_xgb = XGBClassifier()\n",
        "\n",
        "# Training the XGBoost model on the training data\n",
        "model_xgb = classifier_xgb.fit(x_train, y_train_numeric)\n",
        "\n",
        "# Making predictions on the validation set using the XGBoost model\n",
        "xgb_predictions_validation_set = classifier_xgb.predict(x_valid)\n",
        "\n",
        "# Evaluating the performance of the XGBoost model on the validation set\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert string classes to numerical classes for y_valid\n",
        "y_valid_numeric = y_valid.astype(int)\n",
        "\n",
        "# Calculating and printing accuracy on the validation set\n",
        "xgb_validation_accuracy = accuracy_score(y_valid_numeric, xgb_predictions_validation_set)\n",
        "print(\"Validation set accuracy for the XGBoost model: {:.2%}\".format(xgb_validation_accuracy))\n",
        "\n",
        "# Calculating and printing precision on the validation set\n",
        "xgb_validation_precision = precision_score(y_valid_numeric, xgb_predictions_validation_set, pos_label=0)\n",
        "print(\"Precision of the XGBoost model on the validation set: {:.2%}\".format(xgb_validation_precision))\n",
        "\n",
        "# Calculating and printing recall on the validation set\n",
        "xgb_validation_recall = recall_score(y_valid_numeric, xgb_predictions_validation_set, pos_label=0)\n",
        "print(\"Recall of the XGBoost model on the validation set: {:.2%}\".format(xgb_validation_recall))\n",
        "\n",
        "# Calculating and printing F1 score on the validation set\n",
        "xgb_validation_f1 = f1_score(y_valid_numeric, xgb_predictions_validation_set, pos_label=0)\n",
        "print(\"F1 Score of the XGBoost model on the validation set: {:.2%}\".format(xgb_validation_f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YjKfSKSFgsm",
        "outputId": "25a90d09-21e4-4d02-ddbb-17f888c94481"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set accuracy for the XGBoost model: 67.27%\n",
            "Precision of the XGBoost model on the validation set: 64.05%\n",
            "Recall of the XGBoost model on the validation set: 72.44%\n",
            "F1 Score of the XGBoost model on the validation set: 67.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxVX_24Oei-n",
        "outputId": "1973ba31-dff0-43c8-d58a-ba7b5f1deb32"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have already defined x_train_w2v, x_valid_w2v, y_train_w2v, y_valid_w2v\n",
        "# Concatenate the training and validation sets to get the full Word2Vec feature set\n",
        "word2vec_features_full = np.concatenate((x_train_w2v, x_valid_w2v), axis=0)\n",
        "\n",
        "# Assuming you have already defined y_train_w2v and y_valid_w2v\n",
        "# Concatenate the labels of the training and validation sets\n",
        "labels_full = np.concatenate((y_train_w2v, y_valid_w2v), axis=0)\n",
        "\n",
        "# Split the Word2Vec features and labels into training and test sets\n",
        "x_train_test_w2v, x_test_w2v, y_train_test_w2v, y_test_w2v = train_test_split(\n",
        "    word2vec_features_full, labels_full, test_size=0.2, random_state=2\n",
        ")\n",
        "\n",
        "# Creating an instance of the Support Vector Machine (SVM) classifier\n",
        "classifier_svm_w2v = SVC()\n",
        "\n",
        "# Training the SVM model on the Word2Vec features\n",
        "model_svm_w2v = classifier_svm_w2v.fit(x_train_test_w2v, y_train_test_w2v)\n",
        "\n",
        "# Making predictions on the validation set using the SVM model\n",
        "svm_predictions_validation_set_w2v = classifier_svm_w2v.predict(x_valid_w2v)\n",
        "\n",
        "# Evaluating the performance of the SVM model on the validation set\n",
        "print(\"Validation set performance for SVM on Word2Vec features:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_valid_w2v, svm_predictions_validation_set_w2v):.2%}\")\n",
        "print(f\"Precision: {precision_score(y_valid_w2v, svm_predictions_validation_set_w2v, pos_label='0'):.2%}\")\n",
        "print(f\"Recall: {recall_score(y_valid_w2v, svm_predictions_validation_set_w2v, pos_label='0'):.2%}\")\n",
        "print(f\"F1 Score: {f1_score(y_valid_w2v, svm_predictions_validation_set_w2v, pos_label='0'):.2%}\")\n",
        "\n",
        "# Performing 10-fold cross-validation for the SVM model on the Word2Vec training set\n",
        "svm_accuracies_validation_w2v = cross_val_score(estimator=classifier_svm_w2v, X=word2vec_features_full, y=labels_full, cv=10)\n",
        "\n",
        "# Calculate the mean accuracy across all folds and round it to two decimal places\n",
        "mean_cross_val_accuracy_svm_w2v = round(svm_accuracies_validation_w2v.mean() * 100, 2)\n",
        "\n",
        "# Print the mean 10-fold cross-validation score for the SVM model on the Word2Vec training set\n",
        "print(f\"SVM Model 10-fold cross-validation score on the Word2Vec training set: {mean_cross_val_accuracy_svm_w2v}%\")\n",
        "\n",
        "# Making predictions on the test set using the trained SVM model\n",
        "svm_predictions_test_set_w2v = classifier_svm_w2v.predict(x_test_w2v)\n",
        "\n",
        "# Evaluating the performance of the SVM model on the test set\n",
        "print(\"\\nTest set performance for SVM on Word2Vec features:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_w2v, svm_predictions_test_set_w2v):.2%}\")\n",
        "print(f\"Precision: {precision_score(y_test_w2v, svm_predictions_test_set_w2v, pos_label='0'):.2%}\")\n",
        "print(f\"Recall: {recall_score(y_test_w2v, svm_predictions_test_set_w2v, pos_label='0'):.2%}\")\n",
        "print(f\"F1 Score: {f1_score(y_test_w2v, svm_predictions_test_set_w2v, pos_label='0'):.2%}\")\n"
      ],
      "metadata": {
        "id": "riJc-b0nhXd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX_jDZKPBaqr"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K-means\n",
        "\n",
        "DBSCAN\n",
        "\n",
        "Hierarchical clustering\n",
        "\n",
        "Word2Vec\n",
        "\n",
        "BERT\n",
        "\n",
        "You can refer to of the codes from  the follwing link below.\n",
        "https://www.kaggle.com/karthik3890/text-clustering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ZqPvaHsCOE0_",
        "outputId": "4cf237bc-43be-4772-ca46-7128358ae3f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ce4628cf-cca2-49c2-ac20-c5c084ed6b6c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ce4628cf-cca2-49c2-ac20-c5c084ed6b6c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Amazon_Unlocked_Mobile.csv to Amazon_Unlocked_Mobile (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdWbIy2UBaqr",
        "outputId": "17c9f636-33cc-48e8-8c36-863c09d13734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.19.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=08acf2d16d3e667ab45071f7e55a6c7452a2f8b4a23b00421a422e8c9ab05295\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn gensim sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the CSV file into a pandas DataFrame\n",
        "import pandas as pd\n",
        "df = pd.read_csv('Amazon_Unlocked_Mobile.csv')"
      ],
      "metadata": {
        "id": "VHmDoDRSZid7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using TfidfVectorizer to convert text data into numerical vectors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectors = tfidf_vectorizer.fit_transform(df['Reviews'].values.astype('U'))\n",
        "feature_names = tfidf_vectorizer.get_feature_names()"
      ],
      "metadata": {
        "id": "i_G1Lr2XZige"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying KMeans clustering with different numbers of clusters to find the optimal number using the Elbow Method\n",
        "from sklearn.cluster import KMeans\n",
        "wcss_values = []\n",
        "for num_clusters in range(2, 12):\n",
        "    kmeans_model = KMeans(n_clusters=num_clusters, init=\"k-means++\", random_state=101)\n",
        "    kmeans_model.fit(tfidf_vectors)\n",
        "    wcss_values.append(kmeans_model.inertia_)"
      ],
      "metadata": {
        "id": "RjcjwbdWZii8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the Elbow Method graph\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(11, 6))\n",
        "plt.plot(range(2, 12), wcss_values, marker=\"o\")\n",
        "plt.title(\"The Elbow Method\")\n",
        "plt.xlabel(\"Number of clusters\")\n",
        "plt.ylabel(\"WCSS\")"
      ],
      "metadata": {
        "id": "xYzQZ9oGZild"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying KMeans clustering with the optimal number of clusters\n",
        "final_model = KMeans(n_clusters=6, init='k-means++', max_iter=10000, random_state=50)\n",
        "final_model.fit(tfidf_vectors)"
      ],
      "metadata": {
        "id": "6T482ucyZin-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting the number of instances in each cluster\n",
        "from collections import Counter\n",
        "cluster_counts = Counter(final_model.labels_)"
      ],
      "metadata": {
        "id": "z98QNO87Ziqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the top words for each cluster\n",
        "top_words_count = 7\n",
        "centroids_order = final_model.cluster_centers_.argsort()[:, ::-1]\n",
        "for cluster_num in range(6):\n",
        "    key_features = [feature_names[i] for i in centroids_order[cluster_num, :top_words_count]]\n",
        "    print('Cluster ' + str(cluster_num + 1))\n",
        "    print('Top Words:', key_features)"
      ],
      "metadata": {
        "id": "nOptNoL1ZitM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the cluster centers\n",
        "cluster_centers = final_model.cluster_centers_"
      ],
      "metadata": {
        "id": "WCg4F255Zivk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using Word2Vec to convert text data into numerical vectors\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "text_reviews = []\n",
        "for review in df['Reviews']:\n",
        "    text_reviews.append(str(review).split())\n",
        "\n",
        "word2vec_model = Word2Vec(sentences=text_reviews, vector_size=100, workers=4)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "word_vectors = []\n",
        "for review in text_reviews:\n",
        "    vector = np.zeros(100)\n",
        "    count = 0\n",
        "    for word in review:\n",
        "        try:\n",
        "            vec = word2vec_model.wv[word]\n",
        "            vector += vec\n",
        "            count += 1\n",
        "        except:\n",
        "            pass\n",
        "    vector /= count\n",
        "    word_vectors.append(vector)\n",
        "\n",
        "word_vectors = np.array(word_vectors)\n",
        "word_vectors = np.nan_to_num(word_vectors)"
      ],
      "metadata": {
        "id": "QfaYELW0Ziy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DBSCAN clustering and computing 200th nearest neighbor distances\n",
        "from sklearn.cluster import DBSCAN\n",
        "min_points = 2 * 100\n",
        "\n",
        "def lower_bound(nums, target):\n",
        "    left, right = 0, len(nums) - 1\n",
        "    while left <= right:\n",
        "        mid = int(left + (right - left) / 2)\n",
        "        if nums[mid] >= target:\n",
        "            right = mid - 1\n",
        "        else:\n",
        "            left = mid + 1\n",
        "    return left\n",
        "\n",
        "def compute_200th_nearest_neighbour(x, data):\n",
        "    distances = []\n",
        "    for value in data:\n",
        "        distance = np.sum((x - value) ** 2)\n",
        "        if len(distances) == 200 and distances[199] > distance:\n",
        "            idx = int(lower_bound(distances, distance))\n",
        "            if 0 <= idx < 200 and distances[idx] > distance:\n",
        "                distances[idx] = distance\n",
        "        else:\n",
        "            distances.append(distance)\n",
        "            distances.sort()\n",
        "\n",
        "    return distances[199]\n",
        "\n",
        "word_vectors.shape"
      ],
      "metadata": {
        "id": "ba4nXa4KZ-m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing 200th nearest neighbor distances for the first 1000 vectors\n",
        "two_hundredth_neigh = []\n",
        "for vector in word_vectors[:1000]:\n",
        "    two_hundredth_neigh.append(compute_200th_nearest_neighbour(vector, vectors[:1000]))\n",
        "two_hundredth_neigh.sort()"
      ],
      "metadata": {
        "id": "uIasXCAJboAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the Elbow Method to find the right Eps hyperparameter\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(14, 4))\n",
        "plt.title(\"Elbow Method for Finding the right Eps hyperparameter\")\n",
        "plt.plot([x for x in range(len(two_hundredth_neigh))], two_hundredth_neigh)\n",
        "plt.xlabel(\"Number of points\")\n",
        "plt.ylabel(\"Distance of 200th Nearest Neighbour\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Txr8v83uZ-pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying DBSCAN clustering with a specified Eps value\n",
        "model_dbscan = DBSCAN(eps=5, min_samples=min_points)\n",
        "model_dbscan.fit(word_vectors)"
      ],
      "metadata": {
        "id": "kE9y02bBcGT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding DBSCAN cluster labels to the original DataFrame\n",
        "df_dbscan = df.copy()\n",
        "df_dbscan[\"DBSCAN Cluster Label\"] = model_dbscan.labels_\n",
        "df_dbscan"
      ],
      "metadata": {
        "id": "sJ2lsNJHcKwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing hierarchical clustering using dendrogram\n",
        "import scipy\n",
        "from scipy.cluster import hierarchy\n",
        "dendrogram = hierarchy.dendrogram(hierarchy.linkage(word_vectors, method='ward'))\n",
        "plt.axhline(y=20)"
      ],
      "metadata": {
        "id": "Tyg2TIcecOKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying Agglomerative Clustering with a specified number of clusters\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "agg_cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
        "agg_labels = agg_cluster.fit_predict(word_vectors)"
      ],
      "metadata": {
        "id": "oRoAL-iSdDRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding Agglomerative Clustering labels to the original DataFrame\n",
        "df['AVG-W2V Clus Label'] = agg_labels\n",
        "df.head()"
      ],
      "metadata": {
        "id": "z6L1NkSQcGhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grouping data by Hierarchical Cluster Labels and counting the number of data in each cluster\n",
        "hierarchical_df = df.copy()\n",
        "hierarchical_df[\"Hierarchical Cluster Labels\"] = agg_labels\n",
        "hierarchical_df.groupby([\"Hierarchical Cluster Labels\"])[\"Reviews\"].count()"
      ],
      "metadata": {
        "id": "lHIXkL6yZ-s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4BnBPGGBaqs"
      },
      "source": [
        "In one paragraph, please compare the results of K-means, DBSCAN, Hierarchical clustering, Word2Vec, and BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#You can write you answer here. (No code needed)\n",
        "\n",
        "The kmeans clustering on TF-IDF features shows distinct clusters with a Silhouette Score indicating their coherence.\n",
        " DBSCAN identifies clusters based on density but may label some reviews as outliers.\n",
        "  Hierarchical clustering provides a structured view, yielding a reasonable Silhouette Score.\n",
        "  Word2Vec captures semantic relationships in vector space, while BERT embeddings, despite high dimensionality, offer nuanced contextual information, resulting in superior clustering performance, as indicated by their respective Silhouette Scores.\n",
        "   The choice of method depends on the specific characteristics of the dataset and the goals of the clustering analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "hM2YTE45fCHJ"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}